{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "* count real occlusions over the whole dataset\n",
    "\n",
    "```\n",
    "Average length of occlusions: 2.92 frames\n",
    "Average number of occluded frames per video: 24.15 frames\n",
    "Average percentage of occluded frames per video: 3.17%\n",
    "Total number of occluded frames: 2994 out of total for the dataset 101156 \n",
    "```\n",
    "\n",
    "* create X (three?) times as many fake occlusions with ground truth data\n",
    "\n",
    "* \"Target\" for real occlusions: \n",
    "\n",
    "1. random numbers\n",
    "2. linear interpolations\n",
    "3. cubic interpolations\n",
    "\n",
    "* add noise\n",
    "* âœ… create DataLoader object\n",
    "* define train-val-test split\n",
    "* create bi-LSTM object\n",
    "* create training loop\n",
    "* create testing loop\n",
    "* create predict function for one video\n",
    "* save sample .csv of blendshapes for all models (3 so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import ArtistAnimation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import interpolate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# Standardization functions\n",
    "def fit_and_standardize(data):\n",
    "    shape = data.shape\n",
    "    flat = data.reshape((-1, data.shape[-1]))\n",
    "    scaler = StandardScaler().fit(flat)\n",
    "    scaled = scaler.transform(flat).reshape(shape)\n",
    "    return scaled, scaler\n",
    "\n",
    "\n",
    "def standardize(data, scaler):\n",
    "    shape = data.shape\n",
    "    flat = data.reshape((-1, data.shape[-1]))\n",
    "    scaled = scaler.transform(flat).reshape(shape)\n",
    "    return scaled\n",
    "\n",
    "\n",
    "def inv_standardize(data, scaler):\n",
    "    shape = data.shape\n",
    "    flat = data.reshape((-1, data.shape[-1]))\n",
    "    scaled = scaler.inverse_transform(flat).reshape(shape)\n",
    "    return scaled\n",
    "\n",
    "\n",
    "# Data processing function\n",
    "def process_data(data):\n",
    "    gaps = np.isnan(data)\n",
    "    all_null = np.sum(np.sum(gaps, axis=1), axis=1) > gaps.shape[1] * gaps.shape[2] * 0.8\n",
    "    data = data[~all_null, :, :]\n",
    "    gaps = gaps[~all_null, :, :]\n",
    "    keep = ~np.isnan(np.sum(data, axis=(1, 2)))\n",
    "    return data[keep, :, :], gaps[keep, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import ArtistAnimation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import interpolate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, labels=None, occ_prob=0.3, noise_std=0.01):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (np.array): Ground truth data of shape (num_videos, num_frames, blendshapes_dim).\n",
    "            labels (np.array): Binary occlusion labels of shape (num_videos, num_frames).\n",
    "            occ_prob (float): Probability of adding synthetic occlusions.\n",
    "            noise_std (float): Standard deviation of Gaussian noise to add to data.\n",
    "        \"\"\"\n",
    "        self.data = data.copy()\n",
    "        self.labels = labels.copy()\n",
    "        self.data, self.labels, self.mask = self.insert_fake_occlussions(self.data, self.labels, occ_prob=occ_prob) \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def insert_fake_occlussions(self):\n",
    "        data = self.data.copy()\n",
    "        labels = self.labels.copy()\n",
    "        # mask = np.ones_like(labels, dtype=int)  # 1 for real, 0 for synthetic\n",
    "        # create one hot vector that says which data is real 1 and which data is fake 0\n",
    "        mask = np.ones(len(data))   # masking some data\n",
    "        for i in range(len(data)):    # iterate over time\n",
    "            # insert occlussion with probability occ_prob\n",
    "            if np.random.rand() < self.occ_prob:\n",
    "                occ_len = int(np.clip(np.random.normal(2.92, 12.05), 2, 24))   # mean and std from the dataset\n",
    "                print(f\"Inserting occlussion of length {occ_len}\")\n",
    "                \n",
    "                start = np.random.randint(0, len(data[i]) - occ_len)\n",
    "                end = start + occ_len\n",
    "                # check if the occlusion is not already there and update mask only where there wasn't an occlusion already\n",
    "                mask_update_indices = (labels[i, start:end] != 1)\n",
    "                mask[i, start:end][mask_update_indices] = 0  # update mask\n",
    "                labels[i, start:end][mask_update_indices] = 1  # update labels to have 1 for occlusions\n",
    "\n",
    "                mask[i, start:end] = 0  # update mask\n",
    "                labels[i, start:end] = 1  # update labels to have 1 for occlusions\n",
    "                # do nothing to the `data` as it stands for ground truth\n",
    "\n",
    "        # percentage of all occlusions after inserting fake ones\n",
    "        occ_perc = np.mean([np.mean(data[i] == 1) for i in range(len(data))])\n",
    "        print(f\"\\nPercentage of occlusions: {occ_perc}\\n\")\n",
    "        return data, labels, mask\n",
    "    \n",
    "    def add_noise(self, data):\n",
    "        noise = np.random.normal(0, self.noise_std, data.shape)\n",
    "        return data + noise\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "\n",
    "        # Apply noise and transformations\n",
    "        sample = self.add_noise(sample)\n",
    "\n",
    "        if self.labels is not None:\n",
    "            sample_label = self.labels[idx]\n",
    "        else:\n",
    "            sample_label = None\n",
    "\n",
    "        return sample, sample_label\n",
    "    \n",
    "\n",
    "def create_dataloader(all_data, batch_size=32, shuffle=True):\n",
    "    stacked_data = []  # 125 videos, F frames, 51 features\n",
    "    all_labels = []   # 125 videos, F frames\n",
    "    for video, video_frames in all_data.items():\n",
    "        data = []  # F, 51\n",
    "        labels = []  # F\n",
    "        for frame in video_frames:\n",
    "            label = frame.pop(\"occluded\")\n",
    "            blendshapes = [frame[feature] for feature in frame if feature not in [\"Timecode\", \"BlendshapeCount\", \"velocity\", \"smoothed_velocity\"]]\n",
    "            data.append(blendshapes)  # 51 features\n",
    "            labels.append(label)\n",
    "        stacked_data.append(data)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    print(len(stacked_data[0]))\n",
    "    print(stacked_data[0])\n",
    "    print(len(stacked_data))\n",
    "    print(len(all_labels))\n",
    "    dataset = TimeSeriesDataset(stacked_data, all_labels)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n",
      "125\n"
     ]
    }
   ],
   "source": [
    "# read occlusions\n",
    "with np.load(\"occlusions_results.npz\", allow_pickle=True) as data:\n",
    "    video_occlusions_frames = data[\"video_occlusions\"].item()\n",
    "print(len(video_occlusions_frames))\n",
    "\n",
    "\"\"\"# read occlusions\n",
    "with np.load(\"occlusions_results_timecodes.npz\", allow_pickle=True) as data:\n",
    "    video_occlusions = data[\"video_occlusions\"].item()\n",
    "print(len(video_occlusions))\"\"\"\n",
    "\n",
    "# read blendshapes from npz\n",
    "with np.load(\"blendshapes_timecodes_velocities_cubic_interpolated.npz\", allow_pickle=True) as data:\n",
    "    video_blendshapes_cubic = data[\"video_blendshapes\"].item()\n",
    "print(len(video_blendshapes_cubic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_occlusion_labels(video_blendshapes, occlusions):\n",
    "    for video_name, frames in video_blendshapes.items():\n",
    "        occlusion_frames = occlusions.get(video_name, [])  # get occlusions for video_name, if not found return empty list\n",
    "        occlusion_labels = np.zeros(len(frames), dtype=int)\n",
    "        \n",
    "        for start, end in occlusion_frames:\n",
    "            occlusion_labels[start:end+1] = 1\n",
    "        \n",
    "        for i, frame in enumerate(frames):\n",
    "            frame['occluded'] = occlusion_labels[i]\n",
    "    \n",
    "    return video_blendshapes\n",
    "\n",
    "# Add occlusion labels to video_blendshapes_cubic\n",
    "video_blendshapes_cubic = add_occlusion_labels(video_blendshapes_cubic, video_occlusions_frames)\n",
    "video_blendshapes_cubic[\"varg_002_2_pmil\"][0][\"occluded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "{'BrowDownLeft': 0.0632593184709549, 'BrowDownRight': 0.11483088880777359, 'BrowInnerUp': 0.012185418047010899, 'BrowOuterUpLeft': 0.020801110193133354, 'BrowOuterUpRight': 0.009751986712217331, 'CheekPuff': 7.73931333242217e-06, 'CheekSquintLeft': 2.073321354600921e-07, 'CheekSquintRight': 4.6928110464250494e-07, 'EyeBlinkLeft': 0.07462386041879654, 'EyeBlinkRight': 0.029695723205804825, 'EyeLookDownLeft': 0.238837331533432, 'EyeLookDownRight': 0.20948433876037598, 'EyeLookInLeft': 0.01261200848966837, 'EyeLookInRight': 0.22557225823402405, 'EyeLookOutLeft': 0.21054740250110626, 'EyeLookOutRight': 0.01838945783674717, 'EyeLookUpLeft': 0.053056828677654266, 'EyeLookUpRight': 0.05352300405502319, 'EyeSquintLeft': 0.35084065794944763, 'EyeSquintRight': 0.237966388463974, 'EyeWideLeft': 0.012582349590957165, 'EyeWideRight': 0.02496442012488842, 'JawForward': 2.069354013656266e-05, 'JawLeft': 0.0007355318521149457, 'JawOpen': 0.00710756191983819, 'JawRight': 3.4368607884971425e-05, 'MouthClose': 0.0015554100973531604, 'MouthDimpleLeft': 0.001424046466127038, 'MouthDimpleRight': 0.006826256867498159, 'MouthFrownLeft': 0.009982486255466938, 'MouthFrownRight': 0.016212746500968933, 'MouthFunnel': 6.399369158316404e-05, 'MouthLeft': 0.00035318746813572943, 'MouthLowerDownLeft': 0.00012453290401026607, 'MouthLowerDownRight': 7.831249240553007e-05, 'MouthPressLeft': 0.055925894528627396, 'MouthPressRight': 0.19141699373722076, 'MouthPucker': 0.0009072073735296726, 'MouthRight': 0.0009322292171418667, 'MouthRollLower': 0.07038705050945282, 'MouthRollUpper': 0.022503674030303955, 'MouthShrugLower': 0.14682751893997192, 'MouthShrugUpper': 0.0075363339856266975, 'MouthSmileLeft': 0.00046848811325617135, 'MouthSmileRight': 0.0009060713346116245, 'MouthStretchLeft': 0.001704414957202971, 'MouthStretchRight': 0.02370278723537922, 'MouthUpperUpLeft': 3.2762076443759724e-05, 'MouthUpperUpRight': 9.600295743439347e-05, 'NoseSneerLeft': 4.5305185381039337e-07, 'NoseSneerRight': 1.3913585235059145e-06, 'Timecode': '14:57:48:26.504', 'BlendshapeCount': 51, 'velocity': 0, 'smoothed_velocity': 0}\n",
      "101638\n",
      "101638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x3660369a0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_dataloader(video_blendshapes_cubic, batch_size=32, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
